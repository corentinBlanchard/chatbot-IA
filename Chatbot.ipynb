{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/corentinBlanchard/chatbot-IA/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M7SLJGFYcff"
      },
      "source": [
        "#Imports pour recuperation de fichiers a partir de google drive ( ou la DB est stockee)\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-RrjpYbheb4"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzEbTqoyhplz"
      },
      "source": [
        "#Importation des donnees sur la conversation concernant l'IA\n",
        "ia_db = drive.CreateFile({'id':'1asz0LQpmjqAfx7_rc6WxkOeYOS848F2S'})\n",
        "ia_db.GetContentFile('ia.yml') \n",
        "\n",
        "botprofile_db = drive.CreateFile({'id':'1Uuz-UJTelqUrndGa1xFoB9YUbgZckzb-'})\n",
        "botprofile_db.GetContentFile('botprofile.yml') \n",
        "\n",
        "computers_db = drive.CreateFile({'id':'13CsF8ldiPjjwLlp317rnXFy3xs6DX8Bd'})\n",
        "computers_db.GetContentFile('computers.yml')\n",
        "\n",
        "emotion_db = drive.CreateFile({'id':'1zz3HfhaQvnzTmGRk4Ax7L61RNIutnBjS'})\n",
        "emotion_db.GetContentFile('emotion.yml')\n",
        "\n",
        "food_db = drive.CreateFile({'id':'10cTQChOe9zzsGBJyYiCAp-KBk2rYCkTE'})\n",
        "food_db.GetContentFile('food.yml')\n",
        "\n",
        "gossip_db =  drive.CreateFile({'id':'1Rt5to2LxH69v_qcDiYAJsVWjhn_E1c1A'})\n",
        "gossip_db.GetContentFile('gossip.yml')\n",
        "\n",
        "greetings_db =  drive.CreateFile({'id':'1rE2IBzv8JWA-GwAiEaYKUArP13DFyvcK'})\n",
        "greetings_db.GetContentFile('greetings.yml')\n",
        "\n",
        "health_db =  drive.CreateFile({'id':'1Gkg_LJBiRUk10-b9a5npJtMn6UNuEY6g'})\n",
        "health_db.GetContentFile('health.yml')\n",
        "\n",
        "history_db =  drive.CreateFile({'id':'1bKsUE4iGVqwADmqIHwPX3u3rogXs7dcD'})\n",
        "history_db.GetContentFile('history.yml')\n",
        "\n",
        "humor_db =  drive.CreateFile({'id':'1RUcaerZy4Se2zy9guQgAAVA_0N35pO8b'})\n",
        "humor_db.GetContentFile('humor.yml')\n",
        "\n",
        "literature_db =drive.CreateFile({'id':'1TdGULLQEXpiQvFwmB00V21qhfE9LGnq7'})\n",
        "literature_db.GetContentFile('literature.yml')\n",
        "\n",
        "money_db =drive.CreateFile({'id':'1mW98HXxply4YH8wha9BZg1tr09hrlX3W'})\n",
        "money_db.GetContentFile('money.yml')\n",
        "\n",
        "movies_db =drive.CreateFile({'id':'1V3WOQDZmUnFN-ZhG9nXYq4g3LhGMmjck'})\n",
        "movies_db.GetContentFile('movies.yml')\n",
        "\n",
        "politics_db =drive.CreateFile({'id':'1IgVS9x_7r4btfW_LyDg-py7sucRFduKp'})\n",
        "politics_db.GetContentFile('politics.yml')\n",
        "\n",
        "psychology_db =drive.CreateFile({'id':'1RApXTqebauwsMVqOCzC5aO_nB4nsg0NW'})\n",
        "psychology_db.GetContentFile('psychology.yml')\n",
        "\n",
        "science_db =drive.CreateFile({'id':'1AtIFu5F30pxNO-WzOnLNK7aKU7B4lgdM'})\n",
        "science_db.GetContentFile('science.yml')\n",
        "\n",
        "sports_db =drive.CreateFile({'id':'1OsBjPRq9VOCuVl-XSJIp0rTSC0zeJZv-'})\n",
        "sports_db.GetContentFile('sports.yml')\n",
        "\n",
        "trivia_db =drive.CreateFile({'id':'1vTwCh5WJNjEKnFGqRZfsRx7QhzXbkMcJ'})\n",
        "trivia_db.GetContentFile('trivia.yml')\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBEDqOtCiVta"
      },
      "source": [
        "import yaml\n",
        "doc_list = []\n",
        "file = open('ia.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('botprofile.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('computers.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('emotion.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('food.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('gossip.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('greetings.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('health.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('history.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('humor.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('literature.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('money.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('movies.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('politics.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('psychology.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('science.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('sports.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n",
        "file = open('trivia.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "doc_list.append(docs)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQLicVfSd-CZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd0ad12c-6839-42f7-dd7a-dd81a4e3020c"
      },
      "source": [
        "#Create 1 table for questions and 1 table for answers\n",
        "#TODO : import the rest of DB function of len of multiple answers\n",
        "question_table = []\n",
        "answers_table = []\n",
        "\n",
        "for doc in doc_list:\n",
        "  for sentences in doc['conversations']:\n",
        "    if len(sentences) > 2:\n",
        "      answers = sentences[1:]\n",
        "      for a in answers : \n",
        "        question_table.append(sentences[0])\n",
        "        answers_table.append(a)\n",
        "    else:\n",
        "      question_table.append(sentences[0])\n",
        "      answers_table.append(sentences[1])\n",
        "    \n",
        "    \n",
        "\n",
        "print(len(question_table))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjnwGxURsM29"
      },
      "source": [
        "#preprocessing : nous decoupons notre BDD en mots en supprimant la ponctuation afin de cr√©er un dictionnaire\n",
        "words = []\n",
        "#recuperation des mots \n",
        "for sentences in question_table :\n",
        "  question = sentences.split()\n",
        "  #answer = sentences[1].split()\n",
        "  for word in question:\n",
        "    words.append(word.lower())\n",
        "  #for word in answer :\n",
        "  #  words.append(word.lower())"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pcZ8hvevLXD"
      },
      "source": [
        "#suppression de la ponctuation\n",
        "import string\n",
        "import re\n",
        "re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "stripped = [re_punc.sub('', w) for w in words]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_fEt3zGxKq5"
      },
      "source": [
        "#Importation des stopwords\n",
        "#import nltk\n",
        "#nltk.download('stopwords')\n",
        "#from nltk.corpus import stopwords\n",
        "#stop_words=stopwords.words('english')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qClP9enxtrb"
      },
      "source": [
        "#Suppression des stopwords dans notre BDD\n",
        "\n",
        "#import string\n",
        "#import re\n",
        "#from nltk.corpus import stopwords\n",
        "\n",
        "#stop_words = set(stopwords.words('english'))\n",
        "#words = [w for w in stripped if not w in stop_words]\n",
        "words = stripped"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UThvZYqKzGPM"
      },
      "source": [
        "#Stemming pour r√©duction des mots √† leur base\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "# stemming of words\n",
        "porter = PorterStemmer()\n",
        "words = [porter.stem(word) for word in words]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGHw4ZGaz7Ji",
        "outputId": "cfe02319-1f77-4eae-901a-93cd8beb87bd"
      },
      "source": [
        "# Bag of Words\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# create the transform\n",
        "# vectorizer = TfidfVectorizer()\n",
        "vectorizer = CountVectorizer()\n",
        "# tokenize and build vocab\n",
        "vectorizer.fit(words)\n",
        "# encode document\n",
        "vector = vectorizer.transform(words)\n",
        "# summarize encoded vector\n",
        "print(\"vector size : \")\n",
        "print(vector.size)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vector size : \n",
            "2922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSgvMMvN2cYN"
      },
      "source": [
        "# Create table with questions and preprocessing them\n",
        "\n",
        "questions_text = []\n",
        "questions_bow = []\n",
        "\n",
        "\n",
        "for sentences in question_table :\n",
        "  question = sentences.split()\n",
        "  table = []\n",
        "  merged_data = []\n",
        "  \n",
        "  for word in question:\n",
        "    table.append(word.lower())\n",
        "  \n",
        "  table = [re_punc.sub('', w) for w in table]\n",
        "  #table = [w for w in table if not w in stop_words]\n",
        "  table = [porter.stem(word) for word in table]\n",
        "  merged_data.append(' '.join(table))\n",
        "\n",
        "  vector = vectorizer.transform(merged_data)\n",
        "  #print(vector.toarray())\n",
        "\n",
        "  questions_text.append(merged_data)\n",
        "  questions_bow.append(vector)\n",
        "\n",
        "questions_bow_2=[]\n",
        "\n",
        "for element in questions_bow:\n",
        "  questions_bow_2.append(element.toarray())"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJOD2LJHPEzO"
      },
      "source": [
        "#Convert user question to vector using the Bag of Words\n",
        "\n",
        "def convert_question_user(question_user):\n",
        "  question = question_user.split()\n",
        "  table_words_user = []\n",
        "  table_question_user = []\n",
        "\n",
        "\n",
        "  for word in question:\n",
        "    table_words_user.append(word.lower())\n",
        "\n",
        "  table_words_user = [re_punc.sub('', w) for w in table_words_user]\n",
        "  table_words_user = [porter.stem(word) for word in table_words_user]\n",
        "\n",
        "  for element in table_words_user:\n",
        "    if element==\"\":\n",
        "      table_words_user.remove(element)\n",
        "\n",
        "  table_question_user.append(' '.join(table_words_user))\n",
        "  vector_question_user = vectorizer.transform(table_question_user).toarray()\n",
        "  return vector_question_user\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L695Db5DSmeD"
      },
      "source": [
        "#Find the cosine distance to find the most similar sentence\n",
        "\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "import random\n",
        "\n",
        "# cosine similarity\n",
        "def cosine(v1, v2):\n",
        "    if norm(v1) > 0 and norm(v2) > 0:\n",
        "        return dot(v1, v2) / (norm(v1) * norm(v2))\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "def spacy_closest(token_list, vec_to_check):\n",
        "  cosine_max = 0.0\n",
        "  i_elements = []\n",
        "  i=0\n",
        "  for element in token_list:\n",
        "    cos = cosine(element, vec_to_check)\n",
        "    if float(cos) > cosine_max:\n",
        "      cosine_max = cos\n",
        "      i_elements = []\n",
        "      i_elements.append(i)\n",
        "    if float(cos)==cosine_max:\n",
        "      i_elements.append(i)\n",
        "    i = i+1\n",
        "  if cosine_max < 0.2 :\n",
        "    return -1\n",
        "  return random.choice(i_elements)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMg4dIn_eYcs"
      },
      "source": [
        "def conversation(question):\n",
        "  vector_question_user = convert_question_user(question_user=question)\n",
        "  i = spacy_closest(questions_bow_2,vector_question_user[0])\n",
        "  if i == -1 :\n",
        "    return \"I don't understand your question, please reformulate\"\n",
        "  return answers_table[i]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPeeUvKzSOHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5316da0b-7d58-4816-9157-1e9ee9f02412"
      },
      "source": [
        "#Final block to speak with the Chatbot\n",
        "while(True):\n",
        "  question_user = input(\"Please type your question here : \\n\")\n",
        "  if question_user == \"goodbye\":\n",
        "    print(\"Goodbye, have a good day bro !\")\n",
        "    break\n",
        "  print(conversation(question_user))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please type your question here : \n",
            "goodbye\n",
            "Goodbye, have a good day bro !\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}