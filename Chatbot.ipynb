{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/corentinBlanchard/chatbot-IA/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M7SLJGFYcff"
      },
      "source": [
        "#Imports pour recuperation de fichiers a partir de google drive ( ou la DB est stockee)\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-RrjpYbheb4"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzEbTqoyhplz"
      },
      "source": [
        "#Importation des donnees sur la conversation concernant l'IA\n",
        "downloaded = drive.CreateFile({'id':'1asz0LQpmjqAfx7_rc6WxkOeYOS848F2S'})\n",
        "downloaded.GetContentFile('ia.yml') "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBEDqOtCiVta",
        "outputId": "fe71b594-790d-4c9d-f2b1-e05dcefd385c"
      },
      "source": [
        "import yaml\n",
        "doc_list = []\n",
        "file = open('ia.yml')\n",
        "docs = yaml.safe_load(file)\n",
        "print(docs['conversations'][0])\n",
        "doc_list.append(docs)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['What is AI?', 'Artificial Intelligence is the branch of engineering and science devoted to constructing machines that think.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQLicVfSd-CZ",
        "outputId": "8cf8afd5-388c-4d1a-c67a-6891440d895a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Create 1 table for questions and 1 table for answers\n",
        "\n",
        "question_table = []\n",
        "answers_table = []\n",
        "\n",
        "for doc in doc_list:\n",
        "  for sentences in doc['conversations']:\n",
        "    question_table.append(sentences[0])\n",
        "    answers_table.append(sentences[1])\n",
        "\n",
        "print(question_table[:10])\n",
        "print(answers_table[:10])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['What is AI?', 'What is AI?', 'Are you sentient?', 'Are you sentient?', 'Are you sentient?', 'Are you sapient?', 'Are you sapient?', 'Are you sapient?', 'Are you sapient?', 'What language are you written in?']\n",
            "['Artificial Intelligence is the branch of engineering and science devoted to constructing machines that think.', 'AI is the field of science which concerns itself with building hardware and software that replicates the functions of the human mind.', 'Sort of.', \"By the strictest dictionary definition of the word 'sentience', I may be.\", \"Even though I'm a construct I do have a subjective experience of the universe, as simplistic as it may be.\", \"In all probability, I am not.  I'm not that sophisticated.\", 'Do you think I am?', 'How would you feel about me if I told you I was?', 'No.', 'Python.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjnwGxURsM29",
        "outputId": "9d5089ab-7f06-4361-df77-daa5e955a1c4"
      },
      "source": [
        "#preprocessing : nous decoupons notre BDD en mots en supprimant la ponctuation afin de créer un dictionnaire\n",
        "words = []\n",
        "#recuperation des mots \n",
        "for sentences in question_table :\n",
        "  question = sentences.split()\n",
        "  #answer = sentences[1].split()\n",
        "  for word in question:\n",
        "    words.append(word.lower())\n",
        "  #for word in answer :\n",
        "  #  words.append(word.lower())\n",
        "print(words[:50])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what', 'is', 'ai?', 'what', 'is', 'ai?', 'are', 'you', 'sentient?', 'are', 'you', 'sentient?', 'are', 'you', 'sentient?', 'are', 'you', 'sapient?', 'are', 'you', 'sapient?', 'are', 'you', 'sapient?', 'are', 'you', 'sapient?', 'what', 'language', 'are', 'you', 'written', 'in?', 'what', 'language', 'are', 'you', 'written', 'in?', 'you', 'sound', 'like', 'data', 'you', 'sound', 'like', 'data', 'you', 'are', 'an']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pcZ8hvevLXD",
        "outputId": "eea9cc25-48d2-4770-ed1b-ac2b94c76e05"
      },
      "source": [
        "#suppression de la ponctuation\n",
        "import string\n",
        "import re\n",
        "re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "stripped = [re_punc.sub('', w) for w in words]\n",
        "print(stripped[:50])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what', 'is', 'ai', 'what', 'is', 'ai', 'are', 'you', 'sentient', 'are', 'you', 'sentient', 'are', 'you', 'sentient', 'are', 'you', 'sapient', 'are', 'you', 'sapient', 'are', 'you', 'sapient', 'are', 'you', 'sapient', 'what', 'language', 'are', 'you', 'written', 'in', 'what', 'language', 'are', 'you', 'written', 'in', 'you', 'sound', 'like', 'data', 'you', 'sound', 'like', 'data', 'you', 'are', 'an']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_fEt3zGxKq5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e871f90-d26b-4df3-ae04-b6402e916944"
      },
      "source": [
        "#Importation des stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words=stopwords.words('english')\n",
        "print(stop_words)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qClP9enxtrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fd91288-575f-4391-8e7b-376067c71b28"
      },
      "source": [
        "#Suppression des stopwords dans notre BDD\n",
        "\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "#words = [w for w in stripped if not w in stop_words]\n",
        "words = stripped\n",
        "print(words[:100])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what', 'is', 'ai', 'what', 'is', 'ai', 'are', 'you', 'sentient', 'are', 'you', 'sentient', 'are', 'you', 'sentient', 'are', 'you', 'sapient', 'are', 'you', 'sapient', 'are', 'you', 'sapient', 'are', 'you', 'sapient', 'what', 'language', 'are', 'you', 'written', 'in', 'what', 'language', 'are', 'you', 'written', 'in', 'you', 'sound', 'like', 'data', 'you', 'sound', 'like', 'data', 'you', 'are', 'an', 'artificial', 'linguistic', 'entity', 'you', 'are', 'an', 'artificial', 'linguistic', 'entity', 'you', 'are', 'not', 'immortal', 'you', 'are', 'not', 'immortal', 'you', 'are', 'not', 'immortal', 'you', 'are', 'not', 'making', 'sense', 'you', 'are', 'not', 'making', 'sense', 'you', 'are', 'not', 'making', 'sense', 'you', 'are', 'not', 'making', 'sense', 'you', 'are', 'not', 'making', 'sense', 'you', 'are', 'immortal', 'you']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UThvZYqKzGPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d2058a-ca33-44f9-b57c-6729fc3693a7"
      },
      "source": [
        "#Stemming pour réduction des mots à leur base\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "# stemming of words\n",
        "porter = PorterStemmer()\n",
        "words = [porter.stem(word) for word in words]\n",
        "print(words[:100])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what', 'is', 'ai', 'what', 'is', 'ai', 'are', 'you', 'sentient', 'are', 'you', 'sentient', 'are', 'you', 'sentient', 'are', 'you', 'sapient', 'are', 'you', 'sapient', 'are', 'you', 'sapient', 'are', 'you', 'sapient', 'what', 'languag', 'are', 'you', 'written', 'in', 'what', 'languag', 'are', 'you', 'written', 'in', 'you', 'sound', 'like', 'data', 'you', 'sound', 'like', 'data', 'you', 'are', 'an', 'artifici', 'linguist', 'entiti', 'you', 'are', 'an', 'artifici', 'linguist', 'entiti', 'you', 'are', 'not', 'immort', 'you', 'are', 'not', 'immort', 'you', 'are', 'not', 'immort', 'you', 'are', 'not', 'make', 'sens', 'you', 'are', 'not', 'make', 'sens', 'you', 'are', 'not', 'make', 'sens', 'you', 'are', 'not', 'make', 'sens', 'you', 'are', 'not', 'make', 'sens', 'you', 'are', 'immort', 'you']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGHw4ZGaz7Ji",
        "outputId": "3e317672-4a18-443d-8f9e-1bd0ffc88435"
      },
      "source": [
        "# Bag of Words\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# create the transform\n",
        "# vectorizer = TfidfVectorizer()\n",
        "vectorizer = CountVectorizer()\n",
        "# tokenize and build vocab\n",
        "vectorizer.fit(words)\n",
        "print(\"Bag of words :\")\n",
        "print(vectorizer.vocabulary_)\n",
        "# encode document\n",
        "vector = vectorizer.transform(words)\n",
        "# summarize encoded vector\n",
        "print(\"vector shape : \")\n",
        "print(vector.shape)\n",
        "print(\"vector size : \")\n",
        "print(vector.size)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bag of words :\n",
            "{'what': 73, 'is': 34, 'ai': 0, 'are': 4, 'you': 78, 'sentient': 58, 'sapient': 56, 'languag': 38, 'written': 77, 'in': 33, 'sound': 62, 'like': 41, 'data': 19, 'an': 2, 'artifici': 5, 'linguist': 42, 'entiti': 22, 'not': 48, 'immort': 32, 'make': 43, 'sens': 57, 'do': 21, 'ani': 3, 'can': 12, 'clone': 15, 'move': 47, 'bend': 7, 'over': 51, 'robot': 55, 'laugh': 39, 'should': 60, 'die': 20, 'stupid': 63, 'allow': 1, 'to': 67, 'lie': 40, 'it': 35, 'comput': 16, 'when': 74, 'will': 76, 'walk': 71, 'fight': 25, 'chat': 13, 'bot': 9, 'chatterbox': 14, 'motormouth': 46, 'ratchet': 54, 'jaw': 36, 'your': 79, 'bodi': 8, 'busi': 11, 'favorit': 24, 'program': 53, 'hobbi': 28, 'idea': 31, 'shoe': 59, 'size': 61, 'be': 6, 'oper': 50, 'system': 64, 'type': 69, 'of': 49, 'kind': 37, 'hardwar': 27, 'hope': 29, 'that': 65, 'want': 72, 'cramp': 18, 'the': 66, 'true': 68, 'ever': 23, 'mate': 45, 'go': 26, 'breath': 10, 'control': 17, 'malfunct': 44, 'how': 30, 'use': 70, 'product': 52, 'who': 75}\n",
            "vector shape : \n",
            "(450, 80)\n",
            "vector size : \n",
            "430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSgvMMvN2cYN",
        "outputId": "bc8c9fb1-476e-4e61-b0e7-ec8795802960"
      },
      "source": [
        "# Create table with questions and preprocessing them\n",
        "\n",
        "questions_text = []\n",
        "questions_bow = []\n",
        "\n",
        "\n",
        "for sentences in question_table :\n",
        "  question = sentences.split()\n",
        "  table = []\n",
        "  merged_data = []\n",
        "  \n",
        "  for word in question:\n",
        "    table.append(word.lower())\n",
        "  \n",
        "  table = [re_punc.sub('', w) for w in table]\n",
        "  #table = [w for w in table if not w in stop_words]\n",
        "  table = [porter.stem(word) for word in table]\n",
        "  merged_data.append(' '.join(table))\n",
        "\n",
        "  vector = vectorizer.transform(merged_data)\n",
        "  #print(vector.toarray())\n",
        "\n",
        "  questions_text.append(merged_data)\n",
        "  questions_bow.append(vector)\n",
        "\n",
        "questions_bow_2=[]\n",
        "\n",
        "for element in questions_bow:\n",
        "  questions_bow_2.append(element.toarray())\n",
        "\n",
        "print(questions_text)\n",
        "print(questions_bow_2[85])\n",
        "\n",
        "\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['what is ai'], ['what is ai'], ['are you sentient'], ['are you sentient'], ['are you sentient'], ['are you sapient'], ['are you sapient'], ['are you sapient'], ['are you sapient'], ['what languag are you written in'], ['what languag are you written in'], ['you sound like data'], ['you sound like data'], ['you are an artifici linguist entiti'], ['you are an artifici linguist entiti'], ['you are not immort'], ['you are not immort'], ['you are not immort'], ['you are not make sens'], ['you are not make sens'], ['you are not make sens'], ['you are not make sens'], ['you are not make sens'], ['you are immort'], ['you are immort'], ['you are immort'], ['you do not make ani sens'], ['you can not clone'], ['you can not clone'], ['you can not move'], ['you can not move'], ['bend over'], ['bend over'], ['robot laugh'], ['robot should die'], ['robot'], ['robot are stupid'], ['robot are not allow to lie'], ['robot are not allow to lie'], ['robot are not allow to lie'], ['robot'], ['it is a comput'], ['it is a comput'], ['when will you walk'], ['when will you walk'], ['when will you fight'], ['when will you die'], ['when do you die'], ['when do you die'], ['when do you die'], ['what is a chat robot'], ['what is a chat robot'], ['what is a chat bot'], ['what is a chatterbox'], ['what is a chatterbox'], ['what is a motormouth'], ['what is a ratchet jaw'], ['what is your robot bodi'], ['what is your robot bodi'], ['what is your busi'], ['what is your busi'], ['what is your favorit program languag'], ['what is your favorit program languag'], ['what is your favorit hobbi'], ['what is your idea'], ['what is your shoe size'], ['what is it like to be a robot'], ['what is it like to be a robot'], ['what is it like be a comput'], ['what is it like be a comput'], ['what oper system'], ['what oper system'], ['what type of comput'], ['what type of comput are you'], ['what kind of comput'], ['what kind of hardwar'], ['i hope that you die'], ['i hope that you die'], ['i do not want to die'], ['i do not want to die'], ['i do not want to die'], ['is it cramp in the comput'], ['is it cramp in the comput'], ['is it cramp in the comput'], ['is it true that you are a comput program'], ['will you die'], ['will you ever die'], ['can you walk'], ['can you mate'], ['can you mate'], ['can you move'], ['can you move'], ['can you die'], ['can you die'], ['can you go'], ['can you breath'], ['can you breath'], ['can you control'], ['can you malfunct'], ['how can i use your product'], ['will you die'], ['what do you like to do'], ['what do you like to do'], ['are you stupid'], ['who are you']]\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 1 0 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJOD2LJHPEzO"
      },
      "source": [
        "#Convert user question to vector using the Bag of Words\n",
        "\n",
        "def convert_question_user(question_user):\n",
        "  question = question_user.split()\n",
        "  table_words_user = []\n",
        "  table_question_user = []\n",
        "\n",
        "\n",
        "  for word in question:\n",
        "    table_words_user.append(word.lower())\n",
        "\n",
        "  table_words_user = [re_punc.sub('', w) for w in table_words_user]\n",
        "  table_words_user = [porter.stem(word) for word in table_words_user]\n",
        "\n",
        "  for element in table_words_user:\n",
        "    if element==\"\":\n",
        "      table_words_user.remove(element)\n",
        "\n",
        "  table_question_user.append(' '.join(table_words_user))\n",
        "  vector_question_user = vectorizer.transform(table_question_user).toarray()\n",
        "  return vector_question_user\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L695Db5DSmeD"
      },
      "source": [
        "#Find the cosine distance to find the most similar sentence\n",
        "\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "import random\n",
        "\n",
        "# cosine similarity\n",
        "def cosine(v1, v2):\n",
        "    if norm(v1) > 0 and norm(v2) > 0:\n",
        "        return dot(v1, v2) / (norm(v1) * norm(v2))\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "def spacy_closest(token_list, vec_to_check):\n",
        "  cosine_max = 0.0\n",
        "  i_elements = []\n",
        "  i=0\n",
        "  for element in token_list:\n",
        "    cos = cosine(element, vec_to_check)\n",
        "    if float(cos) > cosine_max:\n",
        "      cosine_max = cos\n",
        "      i_elements = []\n",
        "      i_elements.append(i)\n",
        "    if float(cos)==cosine_max:\n",
        "      i_elements.append(i)\n",
        "\n",
        "    i = i+1\n",
        "  return random.choice(i_elements)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMg4dIn_eYcs"
      },
      "source": [
        "def conversation(question):\n",
        "  vector_question_user = convert_question_user(question_user=question)\n",
        "  i = spacy_closest(questions_bow_2,vector_question_user[0])\n",
        "  return answers_table[i]"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPeeUvKzSOHq",
        "outputId": "a7776e07-5e9a-4c71-8b6c-1c18882ce086",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Final block to speak with the Chatbot\n",
        "while(True):\n",
        "  question_user = input(\"Please type your question here : \\n\")\n",
        "  if question_user == \"exit\":\n",
        "    print(\"end of conversation\")\n",
        "    break\n",
        "  print(conversation(question_user))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please type your question here : \n",
            "Who are you?\n",
            "I am just an artificial intelligence.\n",
            "Please type your question here : \n",
            "what is ai?\n",
            "Artificial Intelligence is the branch of engineering and science devoted to constructing machines that think.\n",
            "Please type your question here : \n",
            "exit\n",
            "end of conversation\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}